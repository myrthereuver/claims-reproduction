{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bc1ec4e6-fcf4-4bd6-835f-65172eb9053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0551cdf5-ced6-4123-a168-067bb0dcca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b86888f-2bb6-4d3c-abf0-d2a05cb20f46",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4090e5f8-b29b-43ab-98ef-178e6f0dfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics =[\"abortion\", \"cloning\", \"death_penalty\", \"gun_control\", \"marijuana_legalization\", \"minimum_wage\", \"nuclear_energy\", \"school_uniforms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ede9871d-95a6-42c0-ba45-466976b1796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(topic):\n",
    "    input_file = f'/Users/myrthereuver/PycharmProjects/Claim_reproduction/datasets/ukp/data/complete/{topic}.tsv'\n",
    "    df_current = pd.read_csv(input_file.format(topic), delimiter = \"\\t\", quoting=3)\n",
    "    return df_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "86f6b0a9-f113-4dea-83ef-ee8cf6676dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>retrievedUrl</th>\n",
       "      <th>archivedUrl</th>\n",
       "      <th>sentenceHash</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://2012election.procon.org/view.additional...</td>\n",
       "      <td>http://web.archive.org/web/20150415052859/http...</td>\n",
       "      <td>a1d2d5656a5029eb558812b8259b6567</td>\n",
       "      <td>This means it has to steer monetary policy to ...</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://www.listland.com/top-10-arguments-in-su...</td>\n",
       "      <td>http://web.archive.org/web/20160829133344/http...</td>\n",
       "      <td>a4374eb8cae2c1d52499d0489c7bfb1d</td>\n",
       "      <td>Where did you get that ?</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://www.americamagazine.org/issue/feminist-...</td>\n",
       "      <td>http://web.archive.org/web/20160422223822/http...</td>\n",
       "      <td>825b1a5e0e7915950a2a4a657230d530</td>\n",
       "      <td>Nathanson later became pro-life .</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://www.strangenotions.com/answering-three-...</td>\n",
       "      <td>http://web.archive.org/web/20160916225634/http...</td>\n",
       "      <td>644379f8e228f50f0871270164878c9b</td>\n",
       "      <td>In this case we may never do evil ( directly a...</td>\n",
       "      <td>Argument_against</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://www.healthguidance.org/entry/13561/1/Pr...</td>\n",
       "      <td>http://web.archive.org/web/20160425042210/http...</td>\n",
       "      <td>51eefb36e8947e42403e336536cb00f0</td>\n",
       "      <td>With that I would like to give everyone someth...</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                       retrievedUrl  \\\n",
       "0  abortion  http://2012election.procon.org/view.additional...   \n",
       "1  abortion  http://www.listland.com/top-10-arguments-in-su...   \n",
       "2  abortion  http://www.americamagazine.org/issue/feminist-...   \n",
       "3  abortion  http://www.strangenotions.com/answering-three-...   \n",
       "4  abortion  http://www.healthguidance.org/entry/13561/1/Pr...   \n",
       "\n",
       "                                         archivedUrl  \\\n",
       "0  http://web.archive.org/web/20150415052859/http...   \n",
       "1  http://web.archive.org/web/20160829133344/http...   \n",
       "2  http://web.archive.org/web/20160422223822/http...   \n",
       "3  http://web.archive.org/web/20160916225634/http...   \n",
       "4  http://web.archive.org/web/20160425042210/http...   \n",
       "\n",
       "                       sentenceHash  \\\n",
       "0  a1d2d5656a5029eb558812b8259b6567   \n",
       "1  a4374eb8cae2c1d52499d0489c7bfb1d   \n",
       "2  825b1a5e0e7915950a2a4a657230d530   \n",
       "3  644379f8e228f50f0871270164878c9b   \n",
       "4  51eefb36e8947e42403e336536cb00f0   \n",
       "\n",
       "                                            sentence        annotation    set  \n",
       "0  This means it has to steer monetary policy to ...        NoArgument    val  \n",
       "1                           Where did you get that ?        NoArgument  train  \n",
       "2                  Nathanson later became pro-life .        NoArgument    val  \n",
       "3  In this case we may never do evil ( directly a...  Argument_against  train  \n",
       "4  With that I would like to give everyone someth...        NoArgument   test  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_abortion = import_data(\"abortion\")\n",
    "data_abortion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "23b0ea81-4140-440f-8dea-9f69e170a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [import_data(t) for t in topics]\n",
    "all_data = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18989511-7543-40d3-8ec0-da27091bdcbe",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "43402065-eeb1-4ee8-ae47-d4853ed44b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    2827\n",
       "test      787\n",
       "val       315\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_abortion['set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6df4467a-c205-4ca8-a99a-1867285c27f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set    annotation      \n",
       "test   NoArgument           486\n",
       "       Argument_against     165\n",
       "       Argument_for         136\n",
       "train  NoArgument          1746\n",
       "       Argument_against     591\n",
       "       Argument_for         490\n",
       "val    NoArgument           195\n",
       "       Argument_against      66\n",
       "       Argument_for          54\n",
       "Name: annotation, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_abortion.groupby('set')['annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4a41b3ae-6111-42ab-8b1a-faff4da29145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>retrievedUrl</th>\n",
       "      <th>archivedUrl</th>\n",
       "      <th>sentenceHash</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gun control</td>\n",
       "      <td>http://www.theatlantic.com/magazine/archive/20...</td>\n",
       "      <td>http://web.archive.org/web/20160512215933/http...</td>\n",
       "      <td>7f5b3b58c98b7ee686eb8008f6d8d068</td>\n",
       "      <td>“ I had deep anger when I heard that , ” he to...</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gun control</td>\n",
       "      <td>http://concealedguns.procon.org/</td>\n",
       "      <td>http://web.archive.org/web/20161107160654/http...</td>\n",
       "      <td>5875b612a01b700fdda1d2402efdda16</td>\n",
       "      <td>According to John R. Lott Jr. , PhD , \" when s...</td>\n",
       "      <td>Argument_for</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gun control</td>\n",
       "      <td>http://navajocodetalkers.org/9-principal-pros-...</td>\n",
       "      <td>http://web.archive.org/web/20160506123220/http...</td>\n",
       "      <td>4fb05a0f3420566ddb0c23b9099c39e9</td>\n",
       "      <td>Education Is The Answer More harsh gun control...</td>\n",
       "      <td>Argument_against</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic                                       retrievedUrl  \\\n",
       "0  gun control  http://www.theatlantic.com/magazine/archive/20...   \n",
       "1  gun control                   http://concealedguns.procon.org/   \n",
       "2  gun control  http://navajocodetalkers.org/9-principal-pros-...   \n",
       "\n",
       "                                         archivedUrl  \\\n",
       "0  http://web.archive.org/web/20160512215933/http...   \n",
       "1  http://web.archive.org/web/20161107160654/http...   \n",
       "2  http://web.archive.org/web/20160506123220/http...   \n",
       "\n",
       "                       sentenceHash  \\\n",
       "0  7f5b3b58c98b7ee686eb8008f6d8d068   \n",
       "1  5875b612a01b700fdda1d2402efdda16   \n",
       "2  4fb05a0f3420566ddb0c23b9099c39e9   \n",
       "\n",
       "                                            sentence        annotation    set  \n",
       "0  “ I had deep anger when I heard that , ” he to...        NoArgument  train  \n",
       "1  According to John R. Lott Jr. , PhD , \" when s...      Argument_for  train  \n",
       "2  Education Is The Answer More harsh gun control...  Argument_against  train  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[3][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f561f9-6f7b-47aa-8f0a-07e3f410ffd5",
   "metadata": {},
   "source": [
    "#### Leave Topic Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "24ea041e-d302-459c-965d-23b44b407d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_topic_out(data, left_out_topic):\n",
    "    data = data[data.topic != left_out_topic]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9ed4b6ba-f4d1-4897-a6db-85c3f374aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_abortion = leave_topic_out(all_data, \"abortion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c42eba5a-c4b8-4622-b136-841b8e5898c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_cloning = leave_topic_out(all_data, \"cloning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7ceb6ee5-6858-4644-ab53-4ba49132de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_deathpen = leave_topic_out(all_data, \"death penalty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9461b5d6-fcf5-4c7b-ae5d-d508286ff856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_guncontrol = leave_topic_out(all_data, \"gun control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f9fc44f8-7197-4427-ae6c-db12ba7f5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_marijuana = leave_topic_out(all_data, \"marijuana legalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "595bb215-a60f-411b-9368-a695e30541d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_minwage = leave_topic_out(all_data, \"minimum wage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "991eda9a-2699-4088-8a97-6e0503a59f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_nuclear = leave_topic_out(all_data, \"nuclear energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b2488519-324e-463c-b9fa-59e0a78b9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_schooluni = leave_topic_out(all_data, \"school uniforms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bebf0f1-6739-489b-aa50-2571e2fba430",
   "metadata": {},
   "source": [
    "### Splitting data in pre-defined training, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "17a2e704-8728-4c45-a38f-a84c73200ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(data):\n",
    "    test = data[data.set == 'test']\n",
    "    train = data[data.set == 'train']\n",
    "    dev = data[data.set == 'val']\n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a99b31b4-d943-422d-91f7-c10e0f1af6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"abortion\", \"cloning\", \"death_penalty\", \"gun_control\", \"marijuana_legalization\", \"minimum_wage\", \"nuclear_energy\", \"school_uniforms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a7963126-7572-4c86-b4c8-835490c9fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_train, all_data_val, all_data_test = train_dev_test_split(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ba37d-216a-4d20-a615-dabd08296fb6",
   "metadata": {},
   "source": [
    "#### abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4605ee3e-2cec-4df8-82e9-f4792bebe051",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abortion_train, data_abortion_val, data_abortion_test = train_dev_test_split(data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f2d2a7dd-bf4f-4da0-9a17-8310b83b8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_abortion_train, data_without_abortion_dev, data_without_abortion_test = train_dev_test_split(data_without_abortion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985dd511-9a79-4f5a-b9ea-5394b489df59",
   "metadata": {},
   "source": [
    "#### cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "396d3614-688c-4ec2-8840-630ea8704d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cloning_train, data_cloning_val, data_cloning_test = train_dev_test_split(data_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e5167209-a900-4d89-a958-723ef6d3fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_cloning_train, data_without_cloning_dev, data_without_cloning_test = train_dev_test_split(data_without_cloning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeef219-015f-412f-b625-9086e75a3a93",
   "metadata": {},
   "source": [
    "#### death penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7bd14e0f-cceb-4ae7-8bbc-125beb48a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_death_train, data_death_val, data_death_test = train_dev_test_split(data_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4dcbded4-841a-442a-9ef8-43dffa5b40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_death_train, data_without_death_dev, data_without_death_test = train_dev_test_split(data_without_deathpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea67a43-6aba-42ff-a8a6-0eb44e71d903",
   "metadata": {},
   "source": [
    "#### gun control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "312c96d7-90fe-46a6-a684-a85d84992cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gun_train, data_gun_val, data_gun_test = train_dev_test_split(data_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d80363b0-5159-4d9e-95d2-358b99cb06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_gun_train, data_without_gun_dev, data_without_gun_test = train_dev_test_split(data_without_guncontrol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aefbbf-e54b-4dd1-a710-27fe63ab37c0",
   "metadata": {},
   "source": [
    "#### marijuana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "80335ce0-bb6e-44ac-a4c7-eda632fece47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_marijuana_train, data_marijuana_val, data_marijuana_test = train_dev_test_split(data_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0bb87d73-ea43-46ff-b18b-ecf40a1d0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_marijuana_train, data_without_marijuana_dev, data_without_marijuana_test = train_dev_test_split(data_without_marijuana)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f71e1-7f34-42fd-9f5e-2ed991d01e34",
   "metadata": {},
   "source": [
    "#### minimum wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "66477044-2039-4bec-8c6d-b5ff5e3302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minwage_train, data_minwage_val, data_minwage_test = train_dev_test_split(data_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2fad7d3a-f233-468f-9932-537b695ce6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_minwage_train, data_without_abortion_dev, data_without_abortion_test = train_dev_test_split(data_without_minwage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df05c3e-9cc8-405b-9f91-caeafda81227",
   "metadata": {},
   "source": [
    "#### nuclear energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d6d6bcc2-5ce4-4a79-88b1-d5be1895393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nuclear_train, data_nuclear_val, data_nuclear_test = train_dev_test_split(data_list[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "450d544d-d31a-47e5-82de-7e156411c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_nuclear_train, data_without_nuclear_dev, data_without_nuclear_test = train_dev_test_split(data_without_nuclear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b0aa2-eb0a-42b9-ae7c-f907bf8ac9e0",
   "metadata": {},
   "source": [
    "#### school uniforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ba6a0e19-fd30-49a5-8fe7-daa0a90c5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schooluni_train, data_schooluni_val, data_schooluni_test = train_dev_test_split(data_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c27583ed-f052-4de0-ae30-2ab59d690f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_schooluni_train, data_without_schooluni_dev, data_without_schooluni_test = train_dev_test_split(data_without_schooluni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf218a-b907-4beb-a52e-fd8371137e74",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b75b5-2d19-4041-b502-87ad619f9aec",
   "metadata": {},
   "source": [
    "#### Preprocessing as mentioned in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "65886791-c122-4a54-91ee-ca162336cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6ba8eb0c-4753-45a3-9240-721108628405",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e0dce-7a09-4a36-b33e-19ad4d93232a",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "98c57938-9b8b-4179-bf9e-424493fb085e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827, 6753)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "abortion_train_counts = count_vect.fit_transform(data_abortion_train.sentence)\n",
    "abortion_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "09429367-3033-450b-891f-57cf4dcf7ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827, 6753)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(abortion_train_counts)\n",
    "abortion_train_tf = tf_transformer.transform(abortion_train_counts)\n",
    "abortion_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9bccc5b2-5ba9-44d1-a7bf-066e9b7df102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.LinearSVC()\n",
    "model.fit(abortion_train_tf, data_abortion_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "de7ac192-edd5-4153-803c-64301df1f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import svm\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', svm.LinearSVC()),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ea5dc135-9c5d-4570-8914-eb7342b7905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_hyper = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', svm.LinearSVC(C=0.1)),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3403e72d-05f8-45c4-a079-efd125c9dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"abortion\", \"cloning\", \"death_penalty\", \"gun_control\", \"marijuana_legalization\", \"minimum_wage\", \"nuclear_energy\", \"school_uniforms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d519c-8b82-4ef5-a7d7-894e30a4efee",
   "metadata": {},
   "source": [
    "### train all but abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f84bdbb9-3cbf-49ae-bb93-24f51ccbf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_abortion = text_clf.fit(data_without_abortion_train.sentence, data_without_abortion_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "12cd168c-215b-430e-b6c2-97ad98b8a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_abortion_hyper = text_clf_hyper.fit(data_without_abortion_train.sentence, data_without_abortion_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e595b-d390-49a8-87fb-1f3f399ed0ab",
   "metadata": {},
   "source": [
    "### train all but cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6dee7d95-ca11-4ac1-a38d-8176ae6bdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_cloning = text_clf.fit(data_without_cloning_train.sentence, data_without_cloning_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e0d43472-53c3-48b4-9730-3e3cbf54e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_cloning_hyper = text_clf_hyper.fit(data_without_cloning_train.sentence, data_without_cloning_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5403f-7975-4d25-88b7-bd95dca0e1b5",
   "metadata": {},
   "source": [
    "### train all but nuclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0b18fd4a-474e-4e90-8219-8215deacb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_nuclear = text_clf.fit(data_without_nuclear_train.sentence, data_without_nuclear_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5654dda4-4dd3-4816-9124-743eae6a3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_nuclear_hyper = text_clf_hyper.fit(data_without_nuclear_train.sentence, data_without_nuclear_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f690b6e-190e-4d2b-b8f7-615d8087ed3b",
   "metadata": {},
   "source": [
    "### train all but school uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c9ed43d7-7364-42d0-8d09-8a51f6344ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_schooluni = text_clf.fit(data_without_schooluni_train.sentence, data_without_schooluni_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c49224d1-ed3f-42fc-8080-038fedd15d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_schooluni_hyper = text_clf_hyper.fit(data_without_schooluni_train.sentence, data_without_schooluni_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192e1f0-e540-48b5-a022-b196bae65667",
   "metadata": {},
   "source": [
    "### train all but gun control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "813429dd-3d17-44b2-bbe7-8bf878b1522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_gun = text_clf.fit(data_without_gun_train.sentence, data_without_gun_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "47128829-3c2e-410c-aa0e-636d97ff7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_gun_hyper = text_clf_hyper.fit(data_without_gun_train.sentence, data_without_gun_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d02350-7552-4e73-a921-753b450cc886",
   "metadata": {},
   "source": [
    "### train all but death penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d0852af5-d0b4-4b71-b129-928b2f135604",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_death = text_clf.fit(data_without_death_train.sentence, data_without_death_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "347927c7-403b-407b-a625-0b4c907c7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_death_hyper = text_clf_hyper.fit(data_without_death_train.sentence, data_without_death_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef15c4-13b8-492e-a1cb-d8e3226f61fe",
   "metadata": {},
   "source": [
    "### train all but minimum wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "28c3b674-4868-4ceb-8ce4-1d0fdfd42f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_minwage = text_clf.fit(data_without_minwage_train.sentence, data_without_minwage_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "30f5c2f8-d6fb-4778-89f3-8f2ad44e3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_minwage_hyper = text_clf_hyper.fit(data_without_minwage_train.sentence, data_without_minwage_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390d938-f4dc-462c-93c3-1c5f3c34b4ae",
   "metadata": {},
   "source": [
    "### train all but marijuana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "379e5152-e280-45c3-8fa6-b60f3d3e72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_marijuana = text_clf.fit(data_without_marijuana_train.sentence, data_without_marijuana_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "586ab181-47db-4faf-8dee-216ee8dbd194",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_marijuana_hyper = text_clf_hyper.fit(data_without_marijuana_train.sentence, data_without_marijuana_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff56ed-e8a3-40bc-b1b0-432cd0884fc4",
   "metadata": {},
   "source": [
    "#### Fine-tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b7b002d6-dca9-4cf9-b4e2-17d8f8195051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'clf__C': [0.1,1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ab6f8ac4-ca17-44f5-b339-050c6c675ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(text_clf,param_grid,refit=True,verbose=2)\n",
    "# grid.fit(data_without_marijuana_train.sentence, data_without_marijuana_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "53483c01-57b4-425c-80d7-fe7669c2474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b0c57232-917a-40ba-9ca7-5e8b066e5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a1343-d8da-4668-a35a-ba2cfe4c4781",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac10c3-9bc6-4818-8710-2b2d4fa29301",
   "metadata": {},
   "source": [
    "#### Leave one topic out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "42ea76ec-70f1-48a4-ad0e-4f7250b7a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_model_leavetopic(model, validation, labels=None):\n",
    "    from sklearn import metrics\n",
    "\n",
    "    predicted = model.predict(validation['sentence'])\n",
    "  \n",
    "    print(metrics.classification_report(validation.annotation, predicted, labels=labels, digits=4))\n",
    "    accuracy = np.mean(predicted == validation.annotation)\n",
    "    return f'accuracy = {accuracy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73f38a-f2bc-4b24-aa2c-dcf6c7587aa3",
   "metadata": {},
   "source": [
    "#### train all but abortion, test abortion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c3088-ba78-4940-9123-8c0cbf5fcbf6",
   "metadata": {},
   "source": [
    "#### Non-hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f0b73275-9e66-4cdc-92f4-58cd1423aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4308    0.4242    0.4275        66\n",
      "    Argument_for     0.4348    0.3704    0.4000        54\n",
      "      NoArgument     0.7843    0.8205    0.8020       195\n",
      "\n",
      "        accuracy                         0.6603       315\n",
      "       macro avg     0.5500    0.5384    0.5432       315\n",
      "    weighted avg     0.6503    0.6603    0.6546       315\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6603174603174603'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_abortion, data_abortion_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7b18d65b-ea5a-45c8-b59a-369155dd537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4103    0.2909    0.3404       165\n",
      "    Argument_for     0.3596    0.2353    0.2844       136\n",
      "      NoArgument     0.7005    0.8374    0.7629       486\n",
      "\n",
      "        accuracy                         0.6188       787\n",
      "       macro avg     0.4901    0.4546    0.4626       787\n",
      "    weighted avg     0.5807    0.6188    0.5916       787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6188055908513341'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_abortion, data_abortion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "77cb22ac-4779-46b7-b5ed-dfde8cdab096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4103    0.2909    0.3404       165\n",
      "    Argument_for     0.3596    0.2353    0.2844       136\n",
      "      NoArgument     0.7005    0.8374    0.7629       486\n",
      "\n",
      "        accuracy                         0.6188       787\n",
      "       macro avg     0.4901    0.4546    0.4626       787\n",
      "    weighted avg     0.5807    0.6188    0.5916       787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6188055908513341'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_abortion, data_abortion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469ae1a-1f4c-4369-adba-2ad613d0c0f8",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6d298448-9cf0-44d4-a7b4-510690f0276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5405    0.3030    0.3883        66\n",
      "    Argument_for     0.5517    0.2963    0.3855        54\n",
      "      NoArgument     0.7309    0.9333    0.8198       195\n",
      "\n",
      "        accuracy                         0.6921       315\n",
      "       macro avg     0.6077    0.5109    0.5312       315\n",
      "    weighted avg     0.6603    0.6921    0.6550       315\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.692063492063492'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_abortion_hyper, data_abortion_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c1602-e5c4-40cd-84c2-778fc15e24d0",
   "metadata": {},
   "source": [
    "### train all but school uniform, test school uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168b0b2-9536-4495-9c29-75a23848d5dc",
   "metadata": {},
   "source": [
    "#### Non hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2e433a96-ff93-4da1-882b-64bd802fdfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6000    0.5172    0.5556        58\n",
      "    Argument_for     0.6471    0.5000    0.5641        44\n",
      "      NoArgument     0.7771    0.8777    0.8243       139\n",
      "\n",
      "        accuracy                         0.7220       241\n",
      "       macro avg     0.6747    0.6316    0.6480       241\n",
      "    weighted avg     0.7107    0.7220    0.7121       241\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.7219917012448133'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_schooluni, data_schooluni_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "43effac0-1397-4337-ac90-2e76b011754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5221    0.4041    0.4556       146\n",
      "    Argument_for     0.4867    0.5046    0.4955       109\n",
      "      NoArgument     0.7473    0.8098    0.7773       347\n",
      "\n",
      "        accuracy                         0.6561       602\n",
      "       macro avg     0.5854    0.5728    0.5761       602\n",
      "    weighted avg     0.6455    0.6561    0.6483       602\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6561461794019934'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_schooluni, data_schooluni_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9d8665f7-b373-4fb4-a71c-43224c17dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_model_leavetopic(model_without_schooluni, data_schooluni_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398db882-cd8f-4372-8ad5-c543f0469650",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d475c8e7-0fdb-4c8f-9b70-55c552d8ac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5244    0.2945    0.3772       146\n",
      "    Argument_for     0.5429    0.3486    0.4246       109\n",
      "      NoArgument     0.6978    0.9049    0.7880       347\n",
      "\n",
      "        accuracy                         0.6561       602\n",
      "       macro avg     0.5883    0.5160    0.5299       602\n",
      "    weighted avg     0.6277    0.6561    0.6225       602\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6561461794019934'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_schooluni_hyper, data_schooluni_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330717aa-365b-4f51-80d1-6778d6188584",
   "metadata": {},
   "source": [
    "### train all but gun control, test gun control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd626e00-8306-4297-9586-242ae2953abc",
   "metadata": {},
   "source": [
    "#### Non Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "590bd4f1-f92c-4684-85f2-66d78a2bdbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4000    0.3774    0.3883        53\n",
      "    Argument_for     0.6200    0.4921    0.5487        63\n",
      "      NoArgument     0.7798    0.8618    0.8187       152\n",
      "\n",
      "        accuracy                         0.6791       268\n",
      "       macro avg     0.5999    0.5771    0.5853       268\n",
      "    weighted avg     0.6671    0.6791    0.6701       268\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6791044776119403'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_gun, data_gun_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9c9059a6-162f-439c-b31c-3bdb427787ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.3517    0.3835    0.3669       133\n",
      "    Argument_for     0.4054    0.4747    0.4373       158\n",
      "      NoArgument     0.7817    0.7011    0.7392       378\n",
      "\n",
      "        accuracy                         0.5845       669\n",
      "       macro avg     0.5129    0.5197    0.5145       669\n",
      "    weighted avg     0.6074    0.5845    0.5939       669\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5844544095665172'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_gun, data_gun_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c259d-b3c1-46f7-85dd-fc5fadd24b25",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "46ff6fbc-13c7-41af-b41f-4a903e07d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4333    0.2932    0.3498       133\n",
      "    Argument_for     0.4507    0.4051    0.4267       158\n",
      "      NoArgument     0.7231    0.8360    0.7755       378\n",
      "\n",
      "        accuracy                         0.6263       669\n",
      "       macro avg     0.5357    0.5114    0.5173       669\n",
      "    weighted avg     0.6012    0.6263    0.6085       669\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6263079222720478'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_gun_hyper, data_gun_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2f0c1-5766-4a24-9299-e9b425b677cd",
   "metadata": {},
   "source": [
    "### train all but marijuana, test marijuana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e28b9f-ba33-4a93-abe0-9b29dca84a4f",
   "metadata": {},
   "source": [
    "#### Non Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "08649b82-c8f6-4515-be88-3bf200c342aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5625    0.1800    0.2727        50\n",
      "    Argument_for     0.2727    0.0638    0.1034        47\n",
      "      NoArgument     0.5497    0.9307    0.6912       101\n",
      "\n",
      "        accuracy                         0.5354       198\n",
      "       macro avg     0.4616    0.3915    0.3558       198\n",
      "    weighted avg     0.4872    0.5354    0.4460       198\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5353535353535354'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_marijuana, data_marijuana_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1ed097bf-5883-403f-891c-b26f9c3abdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.3261    0.1190    0.1744       126\n",
      "    Argument_for     0.3000    0.0508    0.0870       118\n",
      "      NoArgument     0.5615    0.9565    0.7076       253\n",
      "\n",
      "        accuracy                         0.5292       497\n",
      "       macro avg     0.3959    0.3755    0.3230       497\n",
      "    weighted avg     0.4397    0.5292    0.4251       497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5291750503018109'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_marijuana, data_marijuana_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1de95c-0803-463e-b4f2-8180dadf2ed3",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b42461c0-407b-4be6-a20e-8039cd306284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.3529    0.0476    0.0839       126\n",
      "    Argument_for     0.5556    0.0424    0.0787       118\n",
      "      NoArgument     0.5329    0.9921    0.6934       253\n",
      "\n",
      "        accuracy                         0.5272       497\n",
      "       macro avg     0.4805    0.3607    0.2853       497\n",
      "    weighted avg     0.4927    0.5272    0.3929       497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5271629778672032'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_marijuana_hyper, data_marijuana_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35d969-f7ac-4f04-bc0d-42eb1d637713",
   "metadata": {},
   "source": [
    "### train all but death penalty, test death penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51528462-40b7-42e8-b793-c8749f040528",
   "metadata": {},
   "source": [
    "#### Non hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e6e4a5c4-001f-48b4-9229-2a8f3fc0b2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6024    0.5556    0.5780        90\n",
      "    Argument_for     0.3333    0.2895    0.3099        38\n",
      "      NoArgument     0.7853    0.8424    0.8129       165\n",
      "\n",
      "        accuracy                         0.6826       293\n",
      "       macro avg     0.5737    0.5625    0.5669       293\n",
      "    weighted avg     0.6705    0.6826    0.6755       293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6825938566552902'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_death, data_death_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "63f4be63-2dfa-4a81-aa74-324156772753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4436    0.5086    0.4739       232\n",
      "    Argument_for     0.2921    0.2524    0.2708       103\n",
      "      NoArgument     0.7207    0.6843    0.7021       396\n",
      "\n",
      "        accuracy                         0.5677       731\n",
      "       macro avg     0.4855    0.4818    0.4823       731\n",
      "    weighted avg     0.5724    0.5677    0.5689       731\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5677154582763337'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_death, data_death_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c810580-44f3-46d4-8d0b-1caee649976e",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9343cd14-21ac-48d6-b4aa-d6fb834bcb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4612    0.4871    0.4738       232\n",
      "    Argument_for     0.2000    0.0485    0.0781       103\n",
      "      NoArgument     0.6855    0.7980    0.7375       396\n",
      "\n",
      "        accuracy                         0.5937       731\n",
      "       macro avg     0.4489    0.4445    0.4298       731\n",
      "    weighted avg     0.5459    0.5937    0.5609       731\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5937072503419972'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_death_hyper, data_death_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea50350-6ca6-415d-8c7c-47bf9cb2ca9d",
   "metadata": {},
   "source": [
    "### train all but minwage, test minwage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48ce1d-2180-48e8-b134-4fca54cb1ddf",
   "metadata": {},
   "source": [
    "#### Non hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "78f1db8c-4b88-4b39-8870-17ac74329b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5135    0.4318    0.4691        44\n",
      "    Argument_for     0.5476    0.5000    0.5227        46\n",
      "      NoArgument     0.7479    0.8241    0.7841       108\n",
      "\n",
      "        accuracy                         0.6616       198\n",
      "       macro avg     0.6030    0.5853    0.5920       198\n",
      "    weighted avg     0.6493    0.6616    0.6534       198\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6616161616161617'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_minwage, data_minwage_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "14f9e1a9-97ec-4b0e-8115-a4895a2379c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5408    0.4775    0.5072       111\n",
      "    Argument_for     0.6105    0.5000    0.5498       116\n",
      "      NoArgument     0.7434    0.8370    0.7875       270\n",
      "\n",
      "        accuracy                         0.6781       497\n",
      "       macro avg     0.6316    0.6048    0.6148       497\n",
      "    weighted avg     0.6672    0.6781    0.6694       497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6780684104627767'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_minwage, data_minwage_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19345e69-5c5d-4755-a9b5-8de31e2a2c36",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "636e10cd-bdd0-414d-95e3-c8c249cbbdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6667    0.4144    0.5111       111\n",
      "    Argument_for     0.6500    0.4483    0.5306       116\n",
      "      NoArgument     0.7126    0.9185    0.8026       270\n",
      "\n",
      "        accuracy                         0.6962       497\n",
      "       macro avg     0.6764    0.5937    0.6148       497\n",
      "    weighted avg     0.6878    0.6962    0.6740       497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6961770623742455'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_minwage_hyper, data_minwage_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37dc4d8-eba2-4749-9f33-8683440523d7",
   "metadata": {},
   "source": [
    "### train all but nuclear, test nuclear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22687e-dbb7-4e6d-869f-eb5e0499de04",
   "metadata": {},
   "source": [
    "#### Non Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1b230bf7-5df4-41f5-a36c-75168c9764da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5082    0.4559    0.4806        68\n",
      "    Argument_for     0.5000    0.5000    0.5000        48\n",
      "      NoArgument     0.7966    0.8294    0.8127       170\n",
      "\n",
      "        accuracy                         0.6853       286\n",
      "       macro avg     0.6016    0.5951    0.5978       286\n",
      "    weighted avg     0.6783    0.6853    0.6813       286\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6853146853146853'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_nuclear, data_nuclear_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2195259c-5834-48b4-a412-4a8e1131ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5245    0.6257    0.5707       171\n",
      "    Argument_for     0.3884    0.3852    0.3868       122\n",
      "      NoArgument     0.8010    0.7406    0.7696       424\n",
      "\n",
      "        accuracy                         0.6527       717\n",
      "       macro avg     0.5713    0.5838    0.5757       717\n",
      "    weighted avg     0.6649    0.6527    0.6570       717\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6527196652719666'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_nuclear, data_nuclear_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb16e4-7a55-4871-9f88-7da94036f712",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "76f3a522-b53d-4dd3-87b4-03bc54852836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5460    0.5205    0.5329       171\n",
      "    Argument_for     0.4925    0.2705    0.3492       122\n",
      "      NoArgument     0.7495    0.8608    0.8013       424\n",
      "\n",
      "        accuracy                         0.6792       717\n",
      "       macro avg     0.5960    0.5506    0.5612       717\n",
      "    weighted avg     0.6572    0.6792    0.6604       717\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6792189679218968'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_nuclear_hyper, data_nuclear_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af044c3f-0c70-4148-a846-9c1c840ab56d",
   "metadata": {},
   "source": [
    "### train all but cloning, test cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c11ac-6e26-43dc-9ffe-c89b3c6e1a96",
   "metadata": {},
   "source": [
    "#### Non hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8f2b9c18-dfda-4d71-8331-9a8dffb186e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6667    0.5075    0.5763        67\n",
      "    Argument_for     0.5273    0.5179    0.5225        56\n",
      "      NoArgument     0.7226    0.8250    0.7704       120\n",
      "\n",
      "        accuracy                         0.6667       243\n",
      "       macro avg     0.6389    0.6168    0.6231       243\n",
      "    weighted avg     0.6622    0.6667    0.6598       243\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6666666666666666'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_cloning, data_cloning_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2919fb11-9cd5-4d58-8b52-0588667a474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5607    0.5774    0.5689       168\n",
      "    Argument_for     0.5039    0.4507    0.4758       142\n",
      "      NoArgument     0.6990    0.7224    0.7105       299\n",
      "\n",
      "        accuracy                         0.6190       609\n",
      "       macro avg     0.5879    0.5835    0.5851       609\n",
      "    weighted avg     0.6154    0.6190    0.6167       609\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6190476190476191'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_cloning, data_cloning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42bcae-1eb0-4f04-ae29-2e9035b8fabd",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5901b5fd-30e2-4498-a2c8-4c5134349cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6597    0.5655    0.6090       168\n",
      "    Argument_for     0.5750    0.3239    0.4144       142\n",
      "      NoArgument     0.6571    0.8462    0.7398       299\n",
      "\n",
      "        accuracy                         0.6470       609\n",
      "       macro avg     0.6306    0.5785    0.5877       609\n",
      "    weighted avg     0.6387    0.6470    0.6278       609\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6469622331691297'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_cloning_hyper, data_cloning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797fd08e-9ecd-4ef5-ad64-c3d1c9148fb3",
   "metadata": {},
   "source": [
    "### Only train on only one topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d29fb-29ed-4958-b20f-1dd4b92a1fbb",
   "metadata": {},
   "source": [
    "#### train abortion, validation gun control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a4486-fadc-4631-8594-ae2a3ba41fa7",
   "metadata": {},
   "source": [
    "### Find Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ab814654-8772-4340-83c8-710852fce14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_featuremodel(X):\n",
    "    #because my method does not work with the Pipeline object, I do the pipeline myself\n",
    "    from sklearn import svm\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    model_abortion = svm.LinearSVC()\n",
    "    count_vect = CountVectorizer()\n",
    "    train_counts = count_vect.fit_transform(X.sentence)\n",
    "    tf_transformer = TfidfTransformer(use_idf=False).fit_transform(train_counts)\n",
    "    model.fit(tf_transformer, X.annotation)\n",
    "    return model, count_vect, tf_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeff8a0-1144-4db1-8808-37d30d95d2a2",
   "metadata": {},
   "source": [
    "#### Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "654a91dc-758a-4808-a2bc-4b9ca1e69d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_model, count_vect_abortion, tf_transformer_abortion = train_featuremodel(data_abortion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ff9bb5e2-6c83-4cd4-9953-f56d6910bab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 6753)\n"
     ]
    }
   ],
   "source": [
    "print(abortion_model.classes_) \n",
    "print(abortion_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2b49ec75-8353-473d-8744-f52e02bc1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_abortion_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "abortion_val_tf = count_vect.transform(data_abortion_test.sentence)\n",
    "abortion_val_idf = tf_transformer.transform(abortion_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5b584da4-5efd-4784-a417-4e8203523d2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-292-08025c02039b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabortion_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabortion_val_idf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_abortion_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "predicted = abortion_model.predict(abortion_val_idf)\n",
    "print(metrics.classification_report(data_abortion_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a758ab-56de-4765-a709-b4a4e98c6868",
   "metadata": {},
   "source": [
    "#### cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4131822-d0f6-4f9b-b370-1416e430399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloning_model, count_vect_cloning, tf_transformer_cloning = train_featuremodel(data_cloning_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a53906-43d3-4d80-be01-7dc0a330df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cloning_model.classes_) \n",
    "print(cloning_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e702ba93-bdfb-443e-82f2-18e77cc79108",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_cloning_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "cloning_val_tf = count_vect.transform(data_cloning_test.sentence)\n",
    "cloning_val_idf = tf_transformer.transform(cloning_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb556e0-ce54-4666-ae20-9d3cac0d28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cloning_model.predict(cloning_val_idf)\n",
    "print(metrics.classification_report(data_cloning_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76654851-da93-4f17-96a2-0ee37d2ca2cf",
   "metadata": {},
   "source": [
    "#### death pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7208c5d-6e15-4c83-a247-995b8f9f87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_model, count_vect_death, tf_transformer_death = train_featuremodel(data_death_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015557a-885c-4140-a770-0b53375f0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(death_model.classes_) \n",
    "print(death_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabd027-1c88-41d0-b3db-42e2ecd602ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_death_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "death_val_tf = count_vect.transform(data_death_test.sentence)\n",
    "death_val_idf = tf_transformer.transform(death_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635899b2-a8fe-4788-9f00-b82740a2b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = death_model.predict(death_val_idf)\n",
    "print(metrics.classification_report(data_death_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b04dd-038b-4b36-a3b8-808b8bb36657",
   "metadata": {},
   "source": [
    "#### gun control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c844e-8a3e-4dd6-9f60-5db33d15a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_model, count_vect_gun, tf_transformer_gun = train_featuremodel(data_gun_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457e58e-42f0-4830-813b-e7842ba068d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gun_model.classes_) \n",
    "print(gun_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49239534-a2ff-490a-9fb9-046b9b44d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_gun_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "gun_val_tf = count_vect.transform(data_gun_test.sentence)\n",
    "gun_val_idf = tf_transformer.transform(gun_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8af905-a80f-4ddf-9504-eacbe5484d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gun_model.predict(gun_val_idf)\n",
    "print(metrics.classification_report(data_gun_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc89f87-429d-4d26-b904-13f27aa0fd2e",
   "metadata": {},
   "source": [
    "#### marijuana legalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6641ca-f7cc-41b3-8d8d-bcd388805563",
   "metadata": {},
   "outputs": [],
   "source": [
    "marijuana_model, count_vect_marijuana, tf_transformer_marijuana = train_featuremodel(data_marijuana_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205e394-8d4a-4a1e-b761-3b4717d9e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(marijuana_model.classes_) \n",
    "print(marijuana_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff28f8a-400f-4eda-a6a0-6aabec3da4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_marijuana_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "marijuana_val_tf = count_vect.transform(data_marijuana_test.sentence)\n",
    "marijuana_val_idf = tf_transformer.transform(marijuana_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9fb82-e096-46b4-9a20-4e391b47c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gun_model.predict(marijuana_val_idf)\n",
    "print(metrics.classification_report(data_marijuana_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f832b9-6b04-4439-9ee4-27285bb391c7",
   "metadata": {},
   "source": [
    "#### Minimum wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3da646-9385-45ce-a0f3-7040638b1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "minwage_model, count_vect_min, tf_transformer_minwage = train_featuremodel(data_minwage_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ae7e0-e888-4b57-8a99-6d23861dbaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(minwage_model.classes_) \n",
    "print(minwage_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d48fb-0fb9-4e3c-8e95-b0c954fd0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_minwage_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "minwage_val_tf = count_vect.transform(data_minwage_test.sentence)\n",
    "minwage_val_idf = tf_transformer.transform(minwage_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6414a-dae0-4da8-abeb-2a2449ad99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = minwage_model.predict(minwage_val_idf)\n",
    "print(metrics.classification_report(data_minwage_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c21da-5166-48f9-b911-29c082b9f753",
   "metadata": {},
   "source": [
    "#### nuclear energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2cf233-e4a1-4f1a-9f1d-d0628ca18e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear_model, count_vect_nuclear, tf_transformer_minwage = train_featuremodel(data_nuclear_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c59b87-8676-4a6b-9c5d-f1fd15e01c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nuclear_model.classes_) \n",
    "print(nuclear_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473cef9-ac92-433e-831e-a77e61bb85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_nuclear_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "nuclear_val_tf = count_vect.transform(data_nuclear_test.sentence)\n",
    "nuclear_val_idf = tf_transformer.transform(nuclear_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c236f3-0b5c-4b58-9a34-70d084097c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = minwage_model.predict(nuclear_val_idf)\n",
    "print(metrics.classification_report(data_nuclear_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2bc5a6-cb7a-43b7-805a-6a5a91259647",
   "metadata": {},
   "source": [
    "#### school uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdcdc12-7fa1-4de2-9d9f-f4c4b3d90eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "schooluni_model, count_vect_schooluni, tf_transformer_schooluni = train_featuremodel(data_schooluni_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae55d67-c242-49ea-ae13-b2d56728ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schooluni_model.classes_) \n",
    "print(schooluni_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3d05b-37d2-48c6-bd00-96fbc2e79380",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_schooluni_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "schooluni_val_tf = count_vect.transform(data_schooluni_test.sentence)\n",
    "schooluni_val_idf = tf_transformer.transform(schooluni_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf0ad9-0c44-471a-9ca4-5e9683c973e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = minwage_model.predict(schooluni_val_idf)\n",
    "print(metrics.classification_report(data_schooluni_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90392e0d-97f0-4eef-b4dd-570bb89054b4",
   "metadata": {},
   "source": [
    "##### The shape of svc.coef_ shows that there are 3 sets of weights. These correspond to the following class label pairs: against/For, Against/NoArg, for/NoArg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed59ae-ad26-41b9-9a1b-2f12229afa28",
   "metadata": {},
   "source": [
    "#### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ae5eb-4216-4cd2-a55c-041b99327472",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model, count_vect_all, tf_transformer_all = train_featuremodel(all_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6791eea-c5fd-4a1a-a088-86a33607f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(all_data_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "all_val_tf = count_vect.transform(all_data_test.sentence)\n",
    "all_val_idf = tf_transformer.transform(all_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54343f7-31c1-41ab-99d4-86cd023d4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = all_model.predict(all_val_idf)\n",
    "print(metrics.classification_report(all_data_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29ac2b-d9f0-43e5-baa1-1d9efcf9fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_coefficients(classifier, class_pair, count_vect, top_features=20):\n",
    "    coefs_with_fns = sorted(zip(model.coef_[class_pair], feature_names)) \n",
    "    df=pd.DataFrame(coefs_with_fns)\n",
    "    df.columns='coefficient','word'\n",
    "    df.sort_values(by='coefficient')\n",
    "    \n",
    "    if class_pair == 0:\n",
    "        positive = \"For\"\n",
    "        negative = \"NoArg\"\n",
    "    if class_pair == 1:\n",
    "        positive = \"NoArg\"\n",
    "        negative = \"For\"\n",
    "    if class_pair == 2:\n",
    "        positive = \"Against\"\n",
    "        negative = \"NoArg\"\n",
    "    \n",
    "#     df_negativeclass = df[df['coefficient'] < 0]\n",
    "    df_negativeclass = df.sort_values(by='coefficient', ascending=False)\n",
    "    df_negative_top = df_negativeclass[:top_features]\n",
    "    \n",
    "#     df_positiveclass = df[df['coefficient'] > 0]\n",
    "    df_positiveclass = df.sort_values(by='coefficient')\n",
    "    df_positive_top = df_positiveclass[:top_features]\n",
    "    \n",
    "    print(negative)\n",
    "    print(df_negative_top)\n",
    "    print(\"//////\")\n",
    "    print(\"######\")\n",
    "    print(\"\\\\\\\\\\\\\")\n",
    "    print(positive)\n",
    "    print(df_positive_top)\n",
    "    \n",
    "    return df, df_positive_top, df_negative_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d03b99-d671-4077-95d2-faf496eaa334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b88f52-2945-4edb-be3a-867096ed6c4c",
   "metadata": {},
   "source": [
    "#### Positive = for, Negative = No Arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c04ee6-a1e5-48d6-ac54-cdd32adc7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, n, p = dataframe_coefficients(all_model, 1, tf_transformer, top_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ea44c-806b-490a-b1dd-ef3fece89e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n[\"word\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177cf511-cbaa-480b-bb2f-097b837cbb7a",
   "metadata": {},
   "source": [
    "#### Positive = Against, Negative = NoArg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6247e-3448-43cf-9b6f-3ecfec537a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, n, p = dataframe_coefficients(all_model, 2, feature_names, top_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762be24-6ad4-4dee-ba20-201a040d8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[\"word\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d259d418-2122-400f-bbee-a4f011d44edd",
   "metadata": {},
   "source": [
    "#### Positive = Against, Negative = For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8835c26-4970-49d7-9e81-6c1d2cde354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, n, p = dataframe_coefficients(all_model, 0, tf_transformer, top_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb6fac-ac1a-4d50-8b66-5c8e5d9830c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n[\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e09d1-f754-4326-90d6-c77422c38991",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Negative coefficients correspond to anti, positive coefficients to neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc91bda-d8eb-4883-ba53-74af9f9e9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NegativeClass = \n",
    "\n",
    "df_PositiveClass = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d3c1f-ee97-4c01-a0c2-df44260accb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b36a99-be3e-4c8f-bd8b-198ef6143e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11609a-d580-4484-81c5-e4e16beb8f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c1043-535c-4049-97e2-245acc0caaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714ed57-48c2-498d-a311-e509b32992ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473de60a-77e0-4990-b099-f12d96b8a835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185b8f6-6b63-4b4f-aa3b-8b79a27930f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b88134-0fbc-4b4a-92b5-2662eedb3dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1923722-d420-4a3c-82a4-8dbbcb80c5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f4b1a-fe91-4e21-9330-bdaf56f7c8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
