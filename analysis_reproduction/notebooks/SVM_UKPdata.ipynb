{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1ec4e6-fcf4-4bd6-835f-65172eb9053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0551cdf5-ced6-4123-a168-067bb0dcca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43aa4c4d-5efd-4fc7-8045-0b09f5b56c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'sklearn' from '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/__init__.py'> 0.24.2\n",
      "<module 'pandas' from '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/__init__.py'> 1.2.4\n",
      "<module 'matplotlib' from '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/__init__.py'> 3.4.2\n",
      "<module 'numpy' from '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/__init__.py'> 1.19.5\n",
      "<module 'seaborn' from '/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/seaborn/__init__.py'> 0.11.1\n"
     ]
    }
   ],
   "source": [
    "for i in [sklearn, pd, matplotlib, np, sn]:\n",
    "    print(i, i.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b86888f-2bb6-4d3c-abf0-d2a05cb20f46",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4090e5f8-b29b-43ab-98ef-178e6f0dfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics =[\"abortion\", \"cloning\", \"death_penalty\", \"gun_control\", \"marijuana_legalization\", \"minimum_wage\", \"nuclear_energy\", \"school_uniforms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede9871d-95a6-42c0-ba45-466976b1796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(topic):\n",
    "    input_file = f'/Users/myrthereuver/PycharmProjects/Claim_reproduction/datasets/ukp/data/complete/{topic}.tsv'\n",
    "    df_current = pd.read_csv(input_file.format(topic), delimiter = \"\\t\", quoting=3)\n",
    "    return df_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f6b0a9-f113-4dea-83ef-ee8cf6676dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>retrievedUrl</th>\n",
       "      <th>archivedUrl</th>\n",
       "      <th>sentenceHash</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://2012election.procon.org/view.additional...</td>\n",
       "      <td>http://web.archive.org/web/20150415052859/http...</td>\n",
       "      <td>a1d2d5656a5029eb558812b8259b6567</td>\n",
       "      <td>This means it has to steer monetary policy to ...</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://www.listland.com/top-10-arguments-in-su...</td>\n",
       "      <td>http://web.archive.org/web/20160829133344/http...</td>\n",
       "      <td>a4374eb8cae2c1d52499d0489c7bfb1d</td>\n",
       "      <td>Where did you get that ?</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://www.americamagazine.org/issue/feminist-...</td>\n",
       "      <td>http://web.archive.org/web/20160422223822/http...</td>\n",
       "      <td>825b1a5e0e7915950a2a4a657230d530</td>\n",
       "      <td>Nathanson later became pro-life .</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://www.strangenotions.com/answering-three-...</td>\n",
       "      <td>http://web.archive.org/web/20160916225634/http...</td>\n",
       "      <td>644379f8e228f50f0871270164878c9b</td>\n",
       "      <td>In this case we may never do evil ( directly a...</td>\n",
       "      <td>Argument_against</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abortion</td>\n",
       "      <td>http://www.healthguidance.org/entry/13561/1/Pr...</td>\n",
       "      <td>http://web.archive.org/web/20160425042210/http...</td>\n",
       "      <td>51eefb36e8947e42403e336536cb00f0</td>\n",
       "      <td>With that I would like to give everyone someth...</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                       retrievedUrl  \\\n",
       "0  abortion  http://2012election.procon.org/view.additional...   \n",
       "1  abortion  http://www.listland.com/top-10-arguments-in-su...   \n",
       "2  abortion  http://www.americamagazine.org/issue/feminist-...   \n",
       "3  abortion  http://www.strangenotions.com/answering-three-...   \n",
       "4  abortion  http://www.healthguidance.org/entry/13561/1/Pr...   \n",
       "\n",
       "                                         archivedUrl  \\\n",
       "0  http://web.archive.org/web/20150415052859/http...   \n",
       "1  http://web.archive.org/web/20160829133344/http...   \n",
       "2  http://web.archive.org/web/20160422223822/http...   \n",
       "3  http://web.archive.org/web/20160916225634/http...   \n",
       "4  http://web.archive.org/web/20160425042210/http...   \n",
       "\n",
       "                       sentenceHash  \\\n",
       "0  a1d2d5656a5029eb558812b8259b6567   \n",
       "1  a4374eb8cae2c1d52499d0489c7bfb1d   \n",
       "2  825b1a5e0e7915950a2a4a657230d530   \n",
       "3  644379f8e228f50f0871270164878c9b   \n",
       "4  51eefb36e8947e42403e336536cb00f0   \n",
       "\n",
       "                                            sentence        annotation    set  \n",
       "0  This means it has to steer monetary policy to ...        NoArgument    val  \n",
       "1                           Where did you get that ?        NoArgument  train  \n",
       "2                  Nathanson later became pro-life .        NoArgument    val  \n",
       "3  In this case we may never do evil ( directly a...  Argument_against  train  \n",
       "4  With that I would like to give everyone someth...        NoArgument   test  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_abortion = import_data(\"abortion\")\n",
    "data_abortion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b0ea81-4140-440f-8dea-9f69e170a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [import_data(t) for t in topics]\n",
    "all_data = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18989511-7543-40d3-8ec0-da27091bdcbe",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43402065-eeb1-4ee8-ae47-d4853ed44b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    2827\n",
       "test      787\n",
       "val       315\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_abortion['set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df4467a-c205-4ca8-a99a-1867285c27f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set    annotation      \n",
       "test   NoArgument           486\n",
       "       Argument_against     165\n",
       "       Argument_for         136\n",
       "train  NoArgument          1746\n",
       "       Argument_against     591\n",
       "       Argument_for         490\n",
       "val    NoArgument           195\n",
       "       Argument_against      66\n",
       "       Argument_for          54\n",
       "Name: annotation, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_abortion.groupby('set')['annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a41b3ae-6111-42ab-8b1a-faff4da29145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>retrievedUrl</th>\n",
       "      <th>archivedUrl</th>\n",
       "      <th>sentenceHash</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gun control</td>\n",
       "      <td>http://www.theatlantic.com/magazine/archive/20...</td>\n",
       "      <td>http://web.archive.org/web/20160512215933/http...</td>\n",
       "      <td>7f5b3b58c98b7ee686eb8008f6d8d068</td>\n",
       "      <td>“ I had deep anger when I heard that , ” he to...</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gun control</td>\n",
       "      <td>http://concealedguns.procon.org/</td>\n",
       "      <td>http://web.archive.org/web/20161107160654/http...</td>\n",
       "      <td>5875b612a01b700fdda1d2402efdda16</td>\n",
       "      <td>According to John R. Lott Jr. , PhD , \" when s...</td>\n",
       "      <td>Argument_for</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gun control</td>\n",
       "      <td>http://navajocodetalkers.org/9-principal-pros-...</td>\n",
       "      <td>http://web.archive.org/web/20160506123220/http...</td>\n",
       "      <td>4fb05a0f3420566ddb0c23b9099c39e9</td>\n",
       "      <td>Education Is The Answer More harsh gun control...</td>\n",
       "      <td>Argument_against</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic                                       retrievedUrl  \\\n",
       "0  gun control  http://www.theatlantic.com/magazine/archive/20...   \n",
       "1  gun control                   http://concealedguns.procon.org/   \n",
       "2  gun control  http://navajocodetalkers.org/9-principal-pros-...   \n",
       "\n",
       "                                         archivedUrl  \\\n",
       "0  http://web.archive.org/web/20160512215933/http...   \n",
       "1  http://web.archive.org/web/20161107160654/http...   \n",
       "2  http://web.archive.org/web/20160506123220/http...   \n",
       "\n",
       "                       sentenceHash  \\\n",
       "0  7f5b3b58c98b7ee686eb8008f6d8d068   \n",
       "1  5875b612a01b700fdda1d2402efdda16   \n",
       "2  4fb05a0f3420566ddb0c23b9099c39e9   \n",
       "\n",
       "                                            sentence        annotation    set  \n",
       "0  “ I had deep anger when I heard that , ” he to...        NoArgument  train  \n",
       "1  According to John R. Lott Jr. , PhD , \" when s...      Argument_for  train  \n",
       "2  Education Is The Answer More harsh gun control...  Argument_against  train  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[3][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f561f9-6f7b-47aa-8f0a-07e3f410ffd5",
   "metadata": {},
   "source": [
    "#### Leave Topic Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ea041e-d302-459c-965d-23b44b407d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_topic_out(data, left_out_topic):\n",
    "    data = data[data.topic != left_out_topic]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed4b6ba-f4d1-4897-a6db-85c3f374aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_abortion = leave_topic_out(all_data, \"abortion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42eba5a-c4b8-4622-b136-841b8e5898c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_cloning = leave_topic_out(all_data, \"cloning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ceb6ee5-6858-4644-ab53-4ba49132de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_deathpen = leave_topic_out(all_data, \"death penalty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9461b5d6-fcf5-4c7b-ae5d-d508286ff856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_guncontrol = leave_topic_out(all_data, \"gun control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9fc44f8-7197-4427-ae6c-db12ba7f5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_marijuana = leave_topic_out(all_data, \"marijuana legalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "595bb215-a60f-411b-9368-a695e30541d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_minwage = leave_topic_out(all_data, \"minimum wage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "991eda9a-2699-4088-8a97-6e0503a59f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_nuclear = leave_topic_out(all_data, \"nuclear energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2488519-324e-463c-b9fa-59e0a78b9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_schooluni = leave_topic_out(all_data, \"school uniforms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bebf0f1-6739-489b-aa50-2571e2fba430",
   "metadata": {},
   "source": [
    "### Splitting data in pre-defined training, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a2e704-8728-4c45-a38f-a84c73200ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(data):\n",
    "    test = data[data.set == 'test']\n",
    "    train = data[data.set == 'train']\n",
    "    dev = data[data.set == 'val']\n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a99b31b4-d943-422d-91f7-c10e0f1af6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"abortion\", \"cloning\", \"death_penalty\", \"gun_control\", \"marijuana_legalization\", \"minimum_wage\", \"nuclear_energy\", \"school_uniforms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7963126-7572-4c86-b4c8-835490c9fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_train, all_data_val, all_data_test = train_dev_test_split(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ba37d-216a-4d20-a615-dabd08296fb6",
   "metadata": {},
   "source": [
    "#### abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4605ee3e-2cec-4df8-82e9-f4792bebe051",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abortion_train, data_abortion_val, data_abortion_test = train_dev_test_split(data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2d2a7dd-bf4f-4da0-9a17-8310b83b8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_abortion_train, data_without_abortion_dev, data_without_abortion_test = train_dev_test_split(data_without_abortion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985dd511-9a79-4f5a-b9ea-5394b489df59",
   "metadata": {},
   "source": [
    "#### cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "396d3614-688c-4ec2-8840-630ea8704d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cloning_train, data_cloning_val, data_cloning_test = train_dev_test_split(data_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5167209-a900-4d89-a958-723ef6d3fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_cloning_train, data_without_cloning_dev, data_without_cloning_test = train_dev_test_split(data_without_cloning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeef219-015f-412f-b625-9086e75a3a93",
   "metadata": {},
   "source": [
    "#### death penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bd14e0f-cceb-4ae7-8bbc-125beb48a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_death_train, data_death_val, data_death_test = train_dev_test_split(data_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dcbded4-841a-442a-9ef8-43dffa5b40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_death_train, data_without_death_dev, data_without_death_test = train_dev_test_split(data_without_deathpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea67a43-6aba-42ff-a8a6-0eb44e71d903",
   "metadata": {},
   "source": [
    "#### gun control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "312c96d7-90fe-46a6-a684-a85d84992cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gun_train, data_gun_val, data_gun_test = train_dev_test_split(data_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d80363b0-5159-4d9e-95d2-358b99cb06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_gun_train, data_without_gun_dev, data_without_gun_test = train_dev_test_split(data_without_guncontrol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aefbbf-e54b-4dd1-a710-27fe63ab37c0",
   "metadata": {},
   "source": [
    "#### marijuana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80335ce0-bb6e-44ac-a4c7-eda632fece47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_marijuana_train, data_marijuana_val, data_marijuana_test = train_dev_test_split(data_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bb87d73-ea43-46ff-b18b-ecf40a1d0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_marijuana_train, data_without_marijuana_dev, data_without_marijuana_test = train_dev_test_split(data_without_marijuana)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f71e1-7f34-42fd-9f5e-2ed991d01e34",
   "metadata": {},
   "source": [
    "#### minimum wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66477044-2039-4bec-8c6d-b5ff5e3302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minwage_train, data_minwage_val, data_minwage_test = train_dev_test_split(data_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fad7d3a-f233-468f-9932-537b695ce6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_minwage_train, data_without_abortion_dev, data_without_abortion_test = train_dev_test_split(data_without_minwage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df05c3e-9cc8-405b-9f91-caeafda81227",
   "metadata": {},
   "source": [
    "#### nuclear energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6d6bcc2-5ce4-4a79-88b1-d5be1895393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nuclear_train, data_nuclear_val, data_nuclear_test = train_dev_test_split(data_list[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "450d544d-d31a-47e5-82de-7e156411c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_nuclear_train, data_without_nuclear_dev, data_without_nuclear_test = train_dev_test_split(data_without_nuclear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b0aa2-eb0a-42b9-ae7c-f907bf8ac9e0",
   "metadata": {},
   "source": [
    "#### school uniforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba6a0e19-fd30-49a5-8fe7-daa0a90c5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schooluni_train, data_schooluni_val, data_schooluni_test = train_dev_test_split(data_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c27583ed-f052-4de0-ae30-2ab59d690f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_schooluni_train, data_without_schooluni_dev, data_without_schooluni_test = train_dev_test_split(data_without_schooluni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf218a-b907-4beb-a52e-fd8371137e74",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b75b5-2d19-4041-b502-87ad619f9aec",
   "metadata": {},
   "source": [
    "#### Preprocessing as mentioned in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65886791-c122-4a54-91ee-ca162336cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ba8eb0c-4753-45a3-9240-721108628405",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e0dce-7a09-4a36-b33e-19ad4d93232a",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98c57938-9b8b-4179-bf9e-424493fb085e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827, 6753)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "abortion_train_counts = count_vect.fit_transform(data_abortion_train.sentence)\n",
    "abortion_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09429367-3033-450b-891f-57cf4dcf7ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2827, 6753)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(abortion_train_counts)\n",
    "abortion_train_tf = tf_transformer.transform(abortion_train_counts)\n",
    "abortion_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9bccc5b2-5ba9-44d1-a7bf-066e9b7df102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.LinearSVC()\n",
    "model.fit(abortion_train_tf, data_abortion_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de7ac192-edd5-4153-803c-64301df1f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import svm\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', svm.LinearSVC()),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea5dc135-9c5d-4570-8914-eb7342b7905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_hyper = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', svm.LinearSVC(C=0.1)),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3403e72d-05f8-45c4-a079-efd125c9dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"abortion\", \"cloning\", \"death_penalty\", \"gun_control\", \"marijuana_legalization\", \"minimum_wage\", \"nuclear_energy\", \"school_uniforms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d519c-8b82-4ef5-a7d7-894e30a4efee",
   "metadata": {},
   "source": [
    "### train all but abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f84bdbb9-3cbf-49ae-bb93-24f51ccbf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_abortion = text_clf.fit(data_without_abortion_train.sentence, data_without_abortion_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12cd168c-215b-430e-b6c2-97ad98b8a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_abortion_hyper = text_clf_hyper.fit(data_without_abortion_train.sentence, data_without_abortion_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e595b-d390-49a8-87fb-1f3f399ed0ab",
   "metadata": {},
   "source": [
    "### train all but cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dee7d95-ca11-4ac1-a38d-8176ae6bdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_cloning = text_clf.fit(data_without_cloning_train.sentence, data_without_cloning_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0d43472-53c3-48b4-9730-3e3cbf54e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_cloning_hyper = text_clf_hyper.fit(data_without_cloning_train.sentence, data_without_cloning_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5403f-7975-4d25-88b7-bd95dca0e1b5",
   "metadata": {},
   "source": [
    "### train all but nuclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b18fd4a-474e-4e90-8219-8215deacb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_nuclear = text_clf.fit(data_without_nuclear_train.sentence, data_without_nuclear_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5654dda4-4dd3-4816-9124-743eae6a3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_nuclear_hyper = text_clf_hyper.fit(data_without_nuclear_train.sentence, data_without_nuclear_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f690b6e-190e-4d2b-b8f7-615d8087ed3b",
   "metadata": {},
   "source": [
    "### train all but school uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9ed43d7-7364-42d0-8d09-8a51f6344ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_schooluni = text_clf.fit(data_without_schooluni_train.sentence, data_without_schooluni_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c49224d1-ed3f-42fc-8080-038fedd15d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_schooluni_hyper = text_clf_hyper.fit(data_without_schooluni_train.sentence, data_without_schooluni_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192e1f0-e540-48b5-a022-b196bae65667",
   "metadata": {},
   "source": [
    "### train all but gun control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "813429dd-3d17-44b2-bbe7-8bf878b1522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_gun = text_clf.fit(data_without_gun_train.sentence, data_without_gun_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47128829-3c2e-410c-aa0e-636d97ff7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_gun_hyper = text_clf_hyper.fit(data_without_gun_train.sentence, data_without_gun_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d02350-7552-4e73-a921-753b450cc886",
   "metadata": {},
   "source": [
    "### train all but death penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0852af5-d0b4-4b71-b129-928b2f135604",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_death = text_clf.fit(data_without_death_train.sentence, data_without_death_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "347927c7-403b-407b-a625-0b4c907c7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_death_hyper = text_clf_hyper.fit(data_without_death_train.sentence, data_without_death_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef15c4-13b8-492e-a1cb-d8e3226f61fe",
   "metadata": {},
   "source": [
    "### train all but minimum wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28c3b674-4868-4ceb-8ce4-1d0fdfd42f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_minwage = text_clf.fit(data_without_minwage_train.sentence, data_without_minwage_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30f5c2f8-d6fb-4778-89f3-8f2ad44e3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_minwage_hyper = text_clf_hyper.fit(data_without_minwage_train.sentence, data_without_minwage_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390d938-f4dc-462c-93c3-1c5f3c34b4ae",
   "metadata": {},
   "source": [
    "### train all but marijuana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "379e5152-e280-45c3-8fa6-b60f3d3e72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_marijuana = text_clf.fit(data_without_marijuana_train.sentence, data_without_marijuana_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "586ab181-47db-4faf-8dee-216ee8dbd194",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_marijuana_hyper = text_clf_hyper.fit(data_without_marijuana_train.sentence, data_without_marijuana_train.annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff56ed-e8a3-40bc-b1b0-432cd0884fc4",
   "metadata": {},
   "source": [
    "#### Fine-tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7b002d6-dca9-4cf9-b4e2-17d8f8195051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'clf__C': [0.1,1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab6f8ac4-ca17-44f5-b339-050c6c675ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(text_clf,param_grid,refit=True,verbose=2)\n",
    "# grid.fit(data_without_marijuana_train.sentence, data_without_marijuana_train.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53483c01-57b4-425c-80d7-fe7669c2474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0c57232-917a-40ba-9ca7-5e8b066e5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a1343-d8da-4668-a35a-ba2cfe4c4781",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac10c3-9bc6-4818-8710-2b2d4fa29301",
   "metadata": {},
   "source": [
    "#### Leave one topic out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42ea76ec-70f1-48a4-ad0e-4f7250b7a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_model_leavetopic(model, validation, labels=None):\n",
    "    from sklearn import metrics\n",
    "\n",
    "    predicted = model.predict(validation['sentence'])\n",
    "  \n",
    "    print(metrics.classification_report(validation.annotation, predicted, labels=labels, digits=4))\n",
    "    accuracy = np.mean(predicted == validation.annotation)\n",
    "    return f'accuracy = {accuracy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73f38a-f2bc-4b24-aa2c-dcf6c7587aa3",
   "metadata": {},
   "source": [
    "#### train all but abortion, test abortion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c3088-ba78-4940-9123-8c0cbf5fcbf6",
   "metadata": {},
   "source": [
    "#### Non-hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0b73275-9e66-4cdc-92f4-58cd1423aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4308    0.4242    0.4275        66\n",
      "    Argument_for     0.4348    0.3704    0.4000        54\n",
      "      NoArgument     0.7843    0.8205    0.8020       195\n",
      "\n",
      "        accuracy                         0.6603       315\n",
      "       macro avg     0.5500    0.5384    0.5432       315\n",
      "    weighted avg     0.6503    0.6603    0.6546       315\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6603174603174603'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_abortion, data_abortion_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b18d65b-ea5a-45c8-b59a-369155dd537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4103    0.2909    0.3404       165\n",
      "    Argument_for     0.3596    0.2353    0.2844       136\n",
      "      NoArgument     0.7005    0.8374    0.7629       486\n",
      "\n",
      "        accuracy                         0.6188       787\n",
      "       macro avg     0.4901    0.4546    0.4626       787\n",
      "    weighted avg     0.5807    0.6188    0.5916       787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6188055908513341'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_abortion, data_abortion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "77cb22ac-4779-46b7-b5ed-dfde8cdab096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4103    0.2909    0.3404       165\n",
      "    Argument_for     0.3596    0.2353    0.2844       136\n",
      "      NoArgument     0.7005    0.8374    0.7629       486\n",
      "\n",
      "        accuracy                         0.6188       787\n",
      "       macro avg     0.4901    0.4546    0.4626       787\n",
      "    weighted avg     0.5807    0.6188    0.5916       787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6188055908513341'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_abortion, data_abortion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469ae1a-1f4c-4369-adba-2ad613d0c0f8",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d298448-9cf0-44d4-a7b4-510690f0276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5405    0.3030    0.3883        66\n",
      "    Argument_for     0.5517    0.2963    0.3855        54\n",
      "      NoArgument     0.7309    0.9333    0.8198       195\n",
      "\n",
      "        accuracy                         0.6921       315\n",
      "       macro avg     0.6077    0.5109    0.5312       315\n",
      "    weighted avg     0.6603    0.6921    0.6550       315\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.692063492063492'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_abortion_hyper, data_abortion_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c1602-e5c4-40cd-84c2-778fc15e24d0",
   "metadata": {},
   "source": [
    "### train all but school uniform, test school uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168b0b2-9536-4495-9c29-75a23848d5dc",
   "metadata": {},
   "source": [
    "#### Non hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e433a96-ff93-4da1-882b-64bd802fdfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6000    0.5172    0.5556        58\n",
      "    Argument_for     0.6471    0.5000    0.5641        44\n",
      "      NoArgument     0.7771    0.8777    0.8243       139\n",
      "\n",
      "        accuracy                         0.7220       241\n",
      "       macro avg     0.6747    0.6316    0.6480       241\n",
      "    weighted avg     0.7107    0.7220    0.7121       241\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.7219917012448133'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_schooluni, data_schooluni_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43effac0-1397-4337-ac90-2e76b011754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5221    0.4041    0.4556       146\n",
      "    Argument_for     0.4867    0.5046    0.4955       109\n",
      "      NoArgument     0.7473    0.8098    0.7773       347\n",
      "\n",
      "        accuracy                         0.6561       602\n",
      "       macro avg     0.5854    0.5728    0.5761       602\n",
      "    weighted avg     0.6455    0.6561    0.6483       602\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6561461794019934'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_schooluni, data_schooluni_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d8665f7-b373-4fb4-a71c-43224c17dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_model_leavetopic(model_without_schooluni, data_schooluni_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398db882-cd8f-4372-8ad5-c543f0469650",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d475c8e7-0fdb-4c8f-9b70-55c552d8ac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5244    0.2945    0.3772       146\n",
      "    Argument_for     0.5429    0.3486    0.4246       109\n",
      "      NoArgument     0.6978    0.9049    0.7880       347\n",
      "\n",
      "        accuracy                         0.6561       602\n",
      "       macro avg     0.5883    0.5160    0.5299       602\n",
      "    weighted avg     0.6277    0.6561    0.6225       602\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6561461794019934'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_schooluni_hyper, data_schooluni_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330717aa-365b-4f51-80d1-6778d6188584",
   "metadata": {},
   "source": [
    "### train all but gun control, test gun control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd626e00-8306-4297-9586-242ae2953abc",
   "metadata": {},
   "source": [
    "#### Non Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "590bd4f1-f92c-4684-85f2-66d78a2bdbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4000    0.3774    0.3883        53\n",
      "    Argument_for     0.6200    0.4921    0.5487        63\n",
      "      NoArgument     0.7798    0.8618    0.8187       152\n",
      "\n",
      "        accuracy                         0.6791       268\n",
      "       macro avg     0.5999    0.5771    0.5853       268\n",
      "    weighted avg     0.6671    0.6791    0.6701       268\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6791044776119403'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_gun, data_gun_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c9059a6-162f-439c-b31c-3bdb427787ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.3517    0.3835    0.3669       133\n",
      "    Argument_for     0.4054    0.4747    0.4373       158\n",
      "      NoArgument     0.7817    0.7011    0.7392       378\n",
      "\n",
      "        accuracy                         0.5845       669\n",
      "       macro avg     0.5129    0.5197    0.5145       669\n",
      "    weighted avg     0.6074    0.5845    0.5939       669\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5844544095665172'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_gun, data_gun_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c259d-b3c1-46f7-85dd-fc5fadd24b25",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46ff6fbc-13c7-41af-b41f-4a903e07d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4333    0.2932    0.3498       133\n",
      "    Argument_for     0.4507    0.4051    0.4267       158\n",
      "      NoArgument     0.7231    0.8360    0.7755       378\n",
      "\n",
      "        accuracy                         0.6263       669\n",
      "       macro avg     0.5357    0.5114    0.5173       669\n",
      "    weighted avg     0.6012    0.6263    0.6085       669\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6263079222720478'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_gun_hyper, data_gun_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2f0c1-5766-4a24-9299-e9b425b677cd",
   "metadata": {},
   "source": [
    "### train all but marijuana, test marijuana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e28b9f-ba33-4a93-abe0-9b29dca84a4f",
   "metadata": {},
   "source": [
    "#### Non Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08649b82-c8f6-4515-be88-3bf200c342aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5625    0.1800    0.2727        50\n",
      "    Argument_for     0.2727    0.0638    0.1034        47\n",
      "      NoArgument     0.5497    0.9307    0.6912       101\n",
      "\n",
      "        accuracy                         0.5354       198\n",
      "       macro avg     0.4616    0.3915    0.3558       198\n",
      "    weighted avg     0.4872    0.5354    0.4460       198\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5353535353535354'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_marijuana, data_marijuana_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ed097bf-5883-403f-891c-b26f9c3abdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.3261    0.1190    0.1744       126\n",
      "    Argument_for     0.3000    0.0508    0.0870       118\n",
      "      NoArgument     0.5615    0.9565    0.7076       253\n",
      "\n",
      "        accuracy                         0.5292       497\n",
      "       macro avg     0.3959    0.3755    0.3230       497\n",
      "    weighted avg     0.4397    0.5292    0.4251       497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5291750503018109'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_marijuana, data_marijuana_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1de95c-0803-463e-b4f2-8180dadf2ed3",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b42461c0-407b-4be6-a20e-8039cd306284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.3529    0.0476    0.0839       126\n",
      "    Argument_for     0.5556    0.0424    0.0787       118\n",
      "      NoArgument     0.5329    0.9921    0.6934       253\n",
      "\n",
      "        accuracy                         0.5272       497\n",
      "       macro avg     0.4805    0.3607    0.2853       497\n",
      "    weighted avg     0.4927    0.5272    0.3929       497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5271629778672032'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_marijuana_hyper, data_marijuana_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35d969-f7ac-4f04-bc0d-42eb1d637713",
   "metadata": {},
   "source": [
    "### train all but death penalty, test death penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51528462-40b7-42e8-b793-c8749f040528",
   "metadata": {},
   "source": [
    "#### Non hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6e4a5c4-001f-48b4-9229-2a8f3fc0b2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6024    0.5556    0.5780        90\n",
      "    Argument_for     0.3333    0.2895    0.3099        38\n",
      "      NoArgument     0.7853    0.8424    0.8129       165\n",
      "\n",
      "        accuracy                         0.6826       293\n",
      "       macro avg     0.5737    0.5625    0.5669       293\n",
      "    weighted avg     0.6705    0.6826    0.6755       293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6825938566552902'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_death, data_death_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "63f4be63-2dfa-4a81-aa74-324156772753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4436    0.5086    0.4739       232\n",
      "    Argument_for     0.2921    0.2524    0.2708       103\n",
      "      NoArgument     0.7207    0.6843    0.7021       396\n",
      "\n",
      "        accuracy                         0.5677       731\n",
      "       macro avg     0.4855    0.4818    0.4823       731\n",
      "    weighted avg     0.5724    0.5677    0.5689       731\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5677154582763337'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_death, data_death_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c810580-44f3-46d4-8d0b-1caee649976e",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9343cd14-21ac-48d6-b4aa-d6fb834bcb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.4612    0.4871    0.4738       232\n",
      "    Argument_for     0.2000    0.0485    0.0781       103\n",
      "      NoArgument     0.6855    0.7980    0.7375       396\n",
      "\n",
      "        accuracy                         0.5937       731\n",
      "       macro avg     0.4489    0.4445    0.4298       731\n",
      "    weighted avg     0.5459    0.5937    0.5609       731\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.5937072503419972'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_death_hyper, data_death_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea50350-6ca6-415d-8c7c-47bf9cb2ca9d",
   "metadata": {},
   "source": [
    "### train all but minwage, test minwage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48ce1d-2180-48e8-b134-4fca54cb1ddf",
   "metadata": {},
   "source": [
    "#### Non hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78f1db8c-4b88-4b39-8870-17ac74329b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5135    0.4318    0.4691        44\n",
      "    Argument_for     0.5476    0.5000    0.5227        46\n",
      "      NoArgument     0.7479    0.8241    0.7841       108\n",
      "\n",
      "        accuracy                         0.6616       198\n",
      "       macro avg     0.6030    0.5853    0.5920       198\n",
      "    weighted avg     0.6493    0.6616    0.6534       198\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6616161616161617'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_minwage, data_minwage_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14f9e1a9-97ec-4b0e-8115-a4895a2379c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5408    0.4775    0.5072       111\n",
      "    Argument_for     0.6105    0.5000    0.5498       116\n",
      "      NoArgument     0.7434    0.8370    0.7875       270\n",
      "\n",
      "        accuracy                         0.6781       497\n",
      "       macro avg     0.6316    0.6048    0.6148       497\n",
      "    weighted avg     0.6672    0.6781    0.6694       497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6780684104627767'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_minwage, data_minwage_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19345e69-5c5d-4755-a9b5-8de31e2a2c36",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "636e10cd-bdd0-414d-95e3-c8c249cbbdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6667    0.4144    0.5111       111\n",
      "    Argument_for     0.6500    0.4483    0.5306       116\n",
      "      NoArgument     0.7126    0.9185    0.8026       270\n",
      "\n",
      "        accuracy                         0.6962       497\n",
      "       macro avg     0.6764    0.5937    0.6148       497\n",
      "    weighted avg     0.6878    0.6962    0.6740       497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6961770623742455'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_minwage_hyper, data_minwage_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37dc4d8-eba2-4749-9f33-8683440523d7",
   "metadata": {},
   "source": [
    "### train all but nuclear, test nuclear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22687e-dbb7-4e6d-869f-eb5e0499de04",
   "metadata": {},
   "source": [
    "#### Non Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b230bf7-5df4-41f5-a36c-75168c9764da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5082    0.4559    0.4806        68\n",
      "    Argument_for     0.5000    0.5000    0.5000        48\n",
      "      NoArgument     0.7966    0.8294    0.8127       170\n",
      "\n",
      "        accuracy                         0.6853       286\n",
      "       macro avg     0.6016    0.5951    0.5978       286\n",
      "    weighted avg     0.6783    0.6853    0.6813       286\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6853146853146853'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_nuclear, data_nuclear_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2195259c-5834-48b4-a412-4a8e1131ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5245    0.6257    0.5707       171\n",
      "    Argument_for     0.3884    0.3852    0.3868       122\n",
      "      NoArgument     0.8010    0.7406    0.7696       424\n",
      "\n",
      "        accuracy                         0.6527       717\n",
      "       macro avg     0.5713    0.5838    0.5757       717\n",
      "    weighted avg     0.6649    0.6527    0.6570       717\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6527196652719666'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_nuclear, data_nuclear_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb16e4-7a55-4871-9f88-7da94036f712",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76f3a522-b53d-4dd3-87b4-03bc54852836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5460    0.5205    0.5329       171\n",
      "    Argument_for     0.4925    0.2705    0.3492       122\n",
      "      NoArgument     0.7495    0.8608    0.8013       424\n",
      "\n",
      "        accuracy                         0.6792       717\n",
      "       macro avg     0.5960    0.5506    0.5612       717\n",
      "    weighted avg     0.6572    0.6792    0.6604       717\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6792189679218968'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_nuclear_hyper, data_nuclear_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af044c3f-0c70-4148-a846-9c1c840ab56d",
   "metadata": {},
   "source": [
    "### train all but cloning, test cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c11ac-6e26-43dc-9ffe-c89b3c6e1a96",
   "metadata": {},
   "source": [
    "#### Non hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f2b9c18-dfda-4d71-8331-9a8dffb186e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6667    0.5075    0.5763        67\n",
      "    Argument_for     0.5273    0.5179    0.5225        56\n",
      "      NoArgument     0.7226    0.8250    0.7704       120\n",
      "\n",
      "        accuracy                         0.6667       243\n",
      "       macro avg     0.6389    0.6168    0.6231       243\n",
      "    weighted avg     0.6622    0.6667    0.6598       243\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6666666666666666'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_cloning, data_cloning_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2919fb11-9cd5-4d58-8b52-0588667a474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.5607    0.5774    0.5689       168\n",
      "    Argument_for     0.5039    0.4507    0.4758       142\n",
      "      NoArgument     0.6990    0.7224    0.7105       299\n",
      "\n",
      "        accuracy                         0.6190       609\n",
      "       macro avg     0.5879    0.5835    0.5851       609\n",
      "    weighted avg     0.6154    0.6190    0.6167       609\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6190476190476191'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_cloning, data_cloning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42bcae-1eb0-4f04-ae29-2e9035b8fabd",
   "metadata": {},
   "source": [
    "#### Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5901b5fd-30e2-4498-a2c8-4c5134349cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against     0.6597    0.5655    0.6090       168\n",
      "    Argument_for     0.5750    0.3239    0.4144       142\n",
      "      NoArgument     0.6571    0.8462    0.7398       299\n",
      "\n",
      "        accuracy                         0.6470       609\n",
      "       macro avg     0.6306    0.5785    0.5877       609\n",
      "    weighted avg     0.6387    0.6470    0.6278       609\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy = 0.6469622331691297'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_model_leavetopic(model_without_cloning_hyper, data_cloning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797fd08e-9ecd-4ef5-ad64-c3d1c9148fb3",
   "metadata": {},
   "source": [
    "### Only train on only one topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d29fb-29ed-4958-b20f-1dd4b92a1fbb",
   "metadata": {},
   "source": [
    "#### train abortion, validation gun control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a4486-fadc-4631-8594-ae2a3ba41fa7",
   "metadata": {},
   "source": [
    "### Find Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab814654-8772-4340-83c8-710852fce14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_featuremodel(X):\n",
    "    #because my method does not work with the Pipeline object, I do the pipeline myself\n",
    "    from sklearn import svm\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    model_abortion = svm.LinearSVC()\n",
    "    count_vect = CountVectorizer()\n",
    "    train_counts = count_vect.fit_transform(X.sentence)\n",
    "    tf_transformer = TfidfTransformer(use_idf=False).fit_transform(train_counts)\n",
    "    model.fit(tf_transformer, X.annotation)\n",
    "    return model, count_vect, tf_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeff8a0-1144-4db1-8808-37d30d95d2a2",
   "metadata": {},
   "source": [
    "#### Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "654a91dc-758a-4808-a2bc-4b9ca1e69d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_model, count_vect_abortion, tf_transformer_abortion = train_featuremodel(data_abortion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ff9bb5e2-6c83-4cd4-9953-f56d6910bab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 6753)\n"
     ]
    }
   ],
   "source": [
    "print(abortion_model.classes_) \n",
    "print(abortion_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b49ec75-8353-473d-8744-f52e02bc1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_abortion_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "abortion_val_tf = count_vect.transform(data_abortion_test.sentence)\n",
    "abortion_val_idf = tf_transformer.transform(abortion_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5b584da4-5efd-4784-a417-4e8203523d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.49      0.49      0.49       165\n",
      "    Argument_for       0.51      0.46      0.48       136\n",
      "      NoArgument       0.79      0.81      0.80       486\n",
      "\n",
      "        accuracy                           0.68       787\n",
      "       macro avg       0.60      0.59      0.59       787\n",
      "    weighted avg       0.68      0.68      0.68       787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = abortion_model.predict(abortion_val_idf)\n",
    "print(metrics.classification_report(data_abortion_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a758ab-56de-4765-a709-b4a4e98c6868",
   "metadata": {},
   "source": [
    "#### cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a4131822-d0f6-4f9b-b370-1416e430399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloning_model, count_vect_cloning, tf_transformer_cloning = train_featuremodel(data_cloning_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91a53906-43d3-4d80-be01-7dc0a330df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 5333)\n"
     ]
    }
   ],
   "source": [
    "print(cloning_model.classes_) \n",
    "print(cloning_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e702ba93-bdfb-443e-82f2-18e77cc79108",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_cloning_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "cloning_val_tf = count_vect.transform(data_cloning_test.sentence)\n",
    "cloning_val_idf = tf_transformer.transform(cloning_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7bb556e0-ce54-4666-ae20-9d3cac0d28b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.59      0.58      0.59       168\n",
      "    Argument_for       0.48      0.51      0.49       142\n",
      "      NoArgument       0.73      0.71      0.72       299\n",
      "\n",
      "        accuracy                           0.63       609\n",
      "       macro avg       0.60      0.60      0.60       609\n",
      "    weighted avg       0.63      0.63      0.63       609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = cloning_model.predict(cloning_val_idf)\n",
    "print(metrics.classification_report(data_cloning_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76654851-da93-4f17-96a2-0ee37d2ca2cf",
   "metadata": {},
   "source": [
    "#### death pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d7208c5d-6e15-4c83-a247-995b8f9f87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_model, count_vect_death, tf_transformer_death = train_featuremodel(data_death_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0015557a-885c-4140-a770-0b53375f0322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 6807)\n"
     ]
    }
   ],
   "source": [
    "print(death_model.classes_) \n",
    "print(death_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3cabd027-1c88-41d0-b3db-42e2ecd602ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_death_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "death_val_tf = count_vect.transform(data_death_test.sentence)\n",
    "death_val_idf = tf_transformer.transform(death_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "635899b2-a8fe-4788-9f00-b82740a2b9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.48      0.54      0.51       232\n",
      "    Argument_for       0.41      0.23      0.30       103\n",
      "      NoArgument       0.70      0.72      0.71       396\n",
      "\n",
      "        accuracy                           0.60       731\n",
      "       macro avg       0.53      0.50      0.50       731\n",
      "    weighted avg       0.59      0.60      0.59       731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = death_model.predict(death_val_idf)\n",
    "print(metrics.classification_report(data_death_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b04dd-038b-4b36-a3b8-808b8bb36657",
   "metadata": {},
   "source": [
    "#### gun control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "228c844e-8a3e-4dd6-9f60-5db33d15a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_model, count_vect_gun, tf_transformer_gun = train_featuremodel(data_gun_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b457e58e-42f0-4830-813b-e7842ba068d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 6320)\n"
     ]
    }
   ],
   "source": [
    "print(gun_model.classes_) \n",
    "print(gun_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "49239534-a2ff-490a-9fb9-046b9b44d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_gun_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "gun_val_tf = count_vect.transform(data_gun_test.sentence)\n",
    "gun_val_idf = tf_transformer.transform(gun_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9f8af905-a80f-4ddf-9504-eacbe5484d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.40      0.36      0.38       133\n",
      "    Argument_for       0.41      0.59      0.49       158\n",
      "      NoArgument       0.79      0.68      0.73       378\n",
      "\n",
      "        accuracy                           0.60       669\n",
      "       macro avg       0.54      0.54      0.53       669\n",
      "    weighted avg       0.63      0.60      0.61       669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = gun_model.predict(gun_val_idf)\n",
    "print(metrics.classification_report(data_gun_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc89f87-429d-4d26-b904-13f27aa0fd2e",
   "metadata": {},
   "source": [
    "#### marijuana legalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b6641ca-f7cc-41b3-8d8d-bcd388805563",
   "metadata": {},
   "outputs": [],
   "source": [
    "marijuana_model, count_vect_marijuana, tf_transformer_marijuana = train_featuremodel(data_marijuana_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1205e394-8d4a-4a1e-b761-3b4717d9e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 5612)\n"
     ]
    }
   ],
   "source": [
    "print(marijuana_model.classes_) \n",
    "print(marijuana_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dff28f8a-400f-4eda-a6a0-6aabec3da4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_marijuana_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "marijuana_val_tf = count_vect.transform(data_marijuana_test.sentence)\n",
    "marijuana_val_idf = tf_transformer.transform(marijuana_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "07b9fb82-e096-46b4-9a20-4e391b47c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.62      0.56      0.59       126\n",
      "    Argument_for       0.60      0.52      0.56       118\n",
      "      NoArgument       0.74      0.82      0.78       253\n",
      "\n",
      "        accuracy                           0.68       497\n",
      "       macro avg       0.65      0.63      0.64       497\n",
      "    weighted avg       0.68      0.68      0.68       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = gun_model.predict(marijuana_val_idf)\n",
    "print(metrics.classification_report(data_marijuana_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f832b9-6b04-4439-9ee4-27285bb391c7",
   "metadata": {},
   "source": [
    "#### Minimum wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5c3da646-9385-45ce-a0f3-7040638b1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "minwage_model, count_vect_min, tf_transformer_minwage = train_featuremodel(data_minwage_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6b5ae7e0-e888-4b57-8a99-6d23861dbaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 4818)\n"
     ]
    }
   ],
   "source": [
    "print(minwage_model.classes_) \n",
    "print(minwage_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b61d48fb-0fb9-4e3c-8e95-b0c954fd0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_minwage_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "minwage_val_tf = count_vect.transform(data_minwage_test.sentence)\n",
    "minwage_val_idf = tf_transformer.transform(minwage_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6ce6414a-dae0-4da8-abeb-2a2449ad99c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.59      0.59      0.59       111\n",
      "    Argument_for       0.62      0.55      0.58       116\n",
      "      NoArgument       0.81      0.84      0.82       270\n",
      "\n",
      "        accuracy                           0.72       497\n",
      "       macro avg       0.67      0.66      0.67       497\n",
      "    weighted avg       0.71      0.72      0.72       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = minwage_model.predict(minwage_val_idf)\n",
    "print(metrics.classification_report(data_minwage_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c21da-5166-48f9-b911-29c082b9f753",
   "metadata": {},
   "source": [
    "#### nuclear energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d2cf233-e4a1-4f1a-9f1d-d0628ca18e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear_model, count_vect_nuclear, tf_transformer_minwage = train_featuremodel(data_nuclear_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d7c59b87-8676-4a6b-9c5d-f1fd15e01c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 7001)\n"
     ]
    }
   ],
   "source": [
    "print(nuclear_model.classes_) \n",
    "print(nuclear_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3473cef9-ac92-433e-831e-a77e61bb85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_nuclear_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "nuclear_val_tf = count_vect.transform(data_nuclear_test.sentence)\n",
    "nuclear_val_idf = tf_transformer.transform(nuclear_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "26c236f3-0b5c-4b58-9a34-70d084097c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.51      0.58      0.54       171\n",
      "    Argument_for       0.36      0.34      0.35       122\n",
      "      NoArgument       0.79      0.75      0.77       424\n",
      "\n",
      "        accuracy                           0.64       717\n",
      "       macro avg       0.55      0.56      0.55       717\n",
      "    weighted avg       0.65      0.64      0.64       717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = minwage_model.predict(nuclear_val_idf)\n",
    "print(metrics.classification_report(data_nuclear_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2bc5a6-cb7a-43b7-805a-6a5a91259647",
   "metadata": {},
   "source": [
    "#### school uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7fdcdc12-7fa1-4de2-9d9f-f4c4b3d90eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "schooluni_model, count_vect_schooluni, tf_transformer_schooluni = train_featuremodel(data_schooluni_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9ae55d67-c242-49ea-ae13-b2d56728ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argument_against' 'Argument_for' 'NoArgument']\n",
      "(3, 5631)\n"
     ]
    }
   ],
   "source": [
    "print(schooluni_model.classes_) \n",
    "print(schooluni_model.coef_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "73a3d05b-37d2-48c6-bd00-96fbc2e79380",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(data_schooluni_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "schooluni_val_tf = count_vect.transform(data_schooluni_test.sentence)\n",
    "schooluni_val_idf = tf_transformer.transform(schooluni_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3eaf0ad9-0c44-471a-9ca4-5e9683c973e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.41      0.40      0.40       146\n",
      "    Argument_for       0.52      0.52      0.52       109\n",
      "      NoArgument       0.77      0.78      0.78       347\n",
      "\n",
      "        accuracy                           0.64       602\n",
      "       macro avg       0.57      0.57      0.57       602\n",
      "    weighted avg       0.64      0.64      0.64       602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = minwage_model.predict(schooluni_val_idf)\n",
    "print(metrics.classification_report(data_schooluni_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90392e0d-97f0-4eef-b4dd-570bb89054b4",
   "metadata": {},
   "source": [
    "##### The shape of svc.coef_ shows that there are 3 sets of weights. These correspond to the following class label pairs: against/For, Against/NoArg, for/NoArg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed59ae-ad26-41b9-9a1b-2f12229afa28",
   "metadata": {},
   "source": [
    "#### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bf1ae5eb-4216-4cd2-a55c-041b99327472",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model, count_vect_all, tf_transformer_all = train_featuremodel(all_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c6791eea-c5fd-4a1a-a088-86a33607f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(all_data_train.sentence)\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tf_transformer.fit(train_counts)\n",
    "\n",
    "all_val_tf = count_vect.transform(all_data_test.sentence)\n",
    "all_val_idf = tf_transformer.transform(all_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f4a888a1-27f3-4755-b5e7-936e20123d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf_transformer.fit_transform(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d54343f7-31c1-41ab-99d4-86cd023d4410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Argument_against       0.51      0.50      0.50      1252\n",
      "    Argument_for       0.46      0.38      0.42      1004\n",
      "      NoArgument       0.75      0.80      0.77      2853\n",
      "\n",
      "        accuracy                           0.64      5109\n",
      "       macro avg       0.57      0.56      0.56      5109\n",
      "    weighted avg       0.63      0.64      0.64      5109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = all_model.predict(all_val_idf)\n",
    "print(metrics.classification_report(all_data_test.annotation, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1f29ac2b-d9f0-43e5-baa1-1d9efcf9fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_coefficients(classifier, class_pair, vect, top_features=20):\n",
    "    feature_names = vect.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(model.coef_[class_pair], feature_names)) \n",
    "    df=pd.DataFrame(coefs_with_fns)\n",
    "    df.columns='coefficient','word'\n",
    "    df.sort_values(by='coefficient')\n",
    "    \n",
    "    if class_pair == 0:\n",
    "        positive = \"For\"\n",
    "        negative = \"NoArg\"\n",
    "    if class_pair == 1:\n",
    "        positive = \"NoArg\"\n",
    "        negative = \"For\"\n",
    "    if class_pair == 2:\n",
    "        positive = \"Against\"\n",
    "        negative = \"NoArg\"\n",
    "    \n",
    "#     df_negativeclass = df[df['coefficient'] < 0]\n",
    "    df_negativeclass = df.sort_values(by='coefficient', ascending=False)\n",
    "    df_negative_top = df_negativeclass[:top_features]\n",
    "    \n",
    "#     df_positiveclass = df[df['coefficient'] > 0]\n",
    "    df_positiveclass = df.sort_values(by='coefficient')\n",
    "    df_positive_top = df_positiveclass[:top_features]\n",
    "    \n",
    "    print(negative)\n",
    "    print(df_negative_top)\n",
    "    print(\"//////\")\n",
    "    print(\"######\")\n",
    "    print(\"\\\\\\\\\\\\\")\n",
    "    print(positive)\n",
    "    print(df_positive_top)\n",
    "    \n",
    "    return df, df_positive_top, df_negative_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d03b99-d671-4077-95d2-faf496eaa334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b88f52-2945-4edb-be3a-867096ed6c4c",
   "metadata": {},
   "source": [
    "#### Positive = for, Negative = No Arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c4c04ee6-a1e5-48d6-ac54-cdd32adc7dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For\n",
      "       coefficient          word\n",
      "19429      2.63061           ivf\n",
      "19428      2.48624      turnover\n",
      "19427      2.27685      murderer\n",
      "19426      2.18511        output\n",
      "19425      1.99262          gang\n",
      "19424      1.96493       dealers\n",
      "19423      1.95868         alley\n",
      "19422      1.94037  unreasonable\n",
      "19421      1.93932        fossil\n",
      "19420      1.92658     concluded\n",
      "//////\n",
      "######\n",
      "\\\\\\\n",
      "NoArg\n",
      "   coefficient           word\n",
      "0     -1.97694         mining\n",
      "1     -1.78137    experiments\n",
      "2     -1.69014        abiding\n",
      "3     -1.55000  disadvantages\n",
      "4     -1.54168           tell\n",
      "5     -1.44593          trump\n",
      "6     -1.35430         earned\n",
      "7     -1.34745     developing\n",
      "8     -1.31154      opponents\n",
      "9     -1.30808          media\n"
     ]
    }
   ],
   "source": [
    "a, n, p = dataframe_coefficients(all_model, 1, count_vect_all , top_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177cf511-cbaa-480b-bb2f-097b837cbb7a",
   "metadata": {},
   "source": [
    "#### Positive = Against, Negative = NoArg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "75e6247e-3448-43cf-9b6f-3ecfec537a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoArg\n",
      "       coefficient       word\n",
      "19429      2.16635     debate\n",
      "19428      2.05186   vaccines\n",
      "19427      2.04929      trump\n",
      "19426      1.91982   election\n",
      "19425      1.86107      lobby\n",
      "19424      1.82859       pros\n",
      "19423      1.78776       2016\n",
      "19422      1.78229    vaccine\n",
      "19421      1.74799    quijano\n",
      "19420      1.69812  determine\n",
      "//////\n",
      "######\n",
      "\\\\\\\n",
      "Against\n",
      "   coefficient           word\n",
      "0     -2.44594       uniforms\n",
      "1     -2.40052       accident\n",
      "2     -2.35500        uniform\n",
      "3     -2.31337        harmful\n",
      "4     -2.30316        minimal\n",
      "5     -2.28751  individuality\n",
      "6     -2.28672       innocent\n",
      "7     -2.28666      deterrent\n",
      "8     -2.26228    radioactive\n",
      "9     -2.14725    destruction\n"
     ]
    }
   ],
   "source": [
    "a, n, p = dataframe_coefficients(all_model, 2, count_vect_all, top_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4762be24-6ad4-4dee-ba20-201a040d8535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19429       debate\n",
       "19428     vaccines\n",
       "19427        trump\n",
       "19426     election\n",
       "19425        lobby\n",
       "19424         pros\n",
       "19423         2016\n",
       "19422      vaccine\n",
       "19421      quijano\n",
       "19420    determine\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[\"word\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d259d418-2122-400f-bbee-a4f011d44edd",
   "metadata": {},
   "source": [
    "#### Positive = Against, Negative = For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c8835c26-4970-49d7-9e81-6c1d2cde354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoArg\n",
      "       coefficient         word\n",
      "19429      2.60146    unethical\n",
      "19428      2.44089   conception\n",
      "19427      2.43518   expression\n",
      "19426      2.35117  radioactive\n",
      "19425      2.29411       boring\n",
      "19424      2.25020   substances\n",
      "19423      2.23436         loss\n",
      "19422      2.07068       regret\n",
      "19421      2.03356       memory\n",
      "19420      2.02297     uniforms\n",
      "//////\n",
      "######\n",
      "\\\\\\\n",
      "For\n",
      "   coefficient        word\n",
      "0     -1.80722    murderer\n",
      "1     -1.71034      remove\n",
      "2     -1.69228    turnover\n",
      "3     -1.64310     counter\n",
      "4     -1.63820      debate\n",
      "5     -1.61784        2009\n",
      "6     -1.56198      output\n",
      "7     -1.56015  department\n",
      "8     -1.54109        2016\n",
      "9     -1.51838     prisons\n"
     ]
    }
   ],
   "source": [
    "a, n, p = dataframe_coefficients(all_model, 0, count_vect_all, top_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b36a99-be3e-4c8f-bd8b-198ef6143e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11609a-d580-4484-81c5-e4e16beb8f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c1043-535c-4049-97e2-245acc0caaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714ed57-48c2-498d-a311-e509b32992ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473de60a-77e0-4990-b099-f12d96b8a835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185b8f6-6b63-4b4f-aa3b-8b79a27930f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b88134-0fbc-4b4a-92b5-2662eedb3dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1923722-d420-4a3c-82a4-8dbbcb80c5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f4b1a-fe91-4e21-9330-bdaf56f7c8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
